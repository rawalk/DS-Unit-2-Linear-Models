{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "AMNG35yV9_5d",
    "outputId": "882405f5-2b1b-47f7-ea75-3dd4d326bcc2"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# If you're on Colab:\n",
    "if 'google.colab' in sys.modules:\n",
    "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/master/data/'\n",
    "    !pip install category_encoders==2.*\n",
    "    !pip install pandas-profiling==2.*\n",
    "\n",
    "# If you're working locally:\n",
    "else:\n",
    "    DATA_PATH = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing relevant libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating pandas dataframes and cleaning up the data + feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-SAM20NV-DPw"
   },
   "outputs": [],
   "source": [
    "# creating elementary  pandas dataframes \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_features = pd.read_csv('test_features.csv')\n",
    "train_features = pd.read_csv('train_features.csv')\n",
    "train_labels = pd.read_csv('train_labels.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wt3ARb_XkjA5"
   },
   "outputs": [],
   "source": [
    "# In order to create a new feature such that the date recorded is in simple date_time format.\n",
    "train_features['date_recorded'] = pd.to_datetime(train_features['date_recorded'], infer_datetime_format=True)\n",
    "test_features['date_recorded'] = pd.to_datetime(test_features['date_recorded'], infer_datetime_format=True)\n",
    "\n",
    "# creating a new feature wpp \n",
    "train_features['wpp'] = train_features['amount_tsh']/train_features['population']\n",
    "test_features['wpp'] = test_features['amount_tsh']/test_features['population']  \n",
    "\n",
    "# cleaning up the NaN and nonesense values\n",
    "train_features['wpp'] = train_features['wpp'].replace([np.inf, -np.inf], np.nan)\n",
    "test_features['wpp'] = test_features['wpp'].replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jo3o0FGPakNR"
   },
   "outputs": [],
   "source": [
    "# checks to see if there are any 0 values in construction year, and checks NaNs values in wpp. \n",
    "def feature_eng_zeros(G):\n",
    "    G['construction'] = G['construction_year'] != 0\n",
    "    G['wpp'] = G['wpp'].replace(np.nan, 0)\n",
    "    return G\n",
    "\n",
    "# running the feature engineering function on the test and train features \n",
    "train_features = feature_eng_zeros(train_features)\n",
    "test_features = feature_eng_zeros(test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "a4P8XgHBk56w",
    "outputId": "2bda77d2-a21f-4ae3-e449-a6d51e4b8f79"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# cconverts each individual datetime feature into a string, such that the model as can use it. \n",
    "def feature_eng_convertDT(N):   \n",
    "    N['year'] = N['date_recorded'].dt.year\n",
    "    N['month'] = N['date_recorded'].dt.month\n",
    "    N['week'] = N['date_recorded'].dt.week\n",
    "    N['age'] = N['year'] -N['construction_year']\n",
    "    N['age'].loc[N['age'] == N['year']] = 0\n",
    "    N['date_recorded'] = N['date_recorded'].astype(str)\n",
    "    return N\n",
    "\n",
    "# running the function on the above. \n",
    "train_features = feature_eng_convertDT(train_features)\n",
    "test_features = feature_eng_convertDT(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zVG9wnrDlB30"
   },
   "outputs": [],
   "source": [
    "# creating a function such that any NaN values get changed over to a random value and not means \n",
    "# the lambda function functions such that it replaces it with a random values within that particular column. \n",
    "def NaNFiller(X):\n",
    "    X['public_meeting'] = X['public_meeting'].fillna(lambda x: random.choice(X[X['public_meeting'] != np.nan])['public_meeting'])\n",
    "    X['permit'] = X['permit'].fillna(lambda x: random.choice(X[X['permit'] != np.nan])['permit'])\n",
    "    X['age'] = X['age'].replace(0, round(X['age'].mean()))\n",
    "    X['gps_height'] = X['gps_height'].replace(0, round(X['gps_height'].mean()))\n",
    "    X['funder']= X['funder'].fillna('other')\n",
    "    return X\n",
    "\n",
    "# Running the NaNFillers function on the train_features. \n",
    "train_features = NaNFiller(train_features)\n",
    "test_features = NaNFiller(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kcAhrMNNmmu2"
   },
   "outputs": [],
   "source": [
    "# defining a function, such that it drops on each function for train_features, test_features, train_labels. \n",
    "def drip_drop_columns(X):\n",
    "    drop_cols = ['quantity_group','construction_year','recorded_by','id','num_private',\n",
    "             'amount_tsh', 'wpt_name','subvillage','management_group']\n",
    "    X = X.drop(columns= drop_cols)\n",
    "    return X\n",
    "\n",
    "# dropping the columsn using hte function. \n",
    "train_features = drip_drop_columns(train_features)\n",
    "test_features = drip_drop_columns(test_features)\n",
    "train_labels = train_labels.drop(columns='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# doing test train split split to begin model testing\n",
    "\n",
    "ordinal encoding + MinMaxScaler instead of StandardScaler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_tj8kgkQndxn"
   },
   "outputs": [],
   "source": [
    "# doing a test train split to begin parsing the columns. \n",
    "X_train, X_val, y_train, y_val = train_test_split(train_features,train_labels, random_state=42, test_size=.2)\n",
    "X_test = test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rik4AKHTanDN",
    "outputId": "b1747248-fc01-4053-da7f-ed9aafa81b02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59400, 37), (14358, 37))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape, test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "miYmlluvpXcY"
   },
   "outputs": [],
   "source": [
    "# using ordinal encoder as the encoder. \n",
    "encoder = ce.OrdinalEncoder()\n",
    "# Fit & Transform\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "\n",
    "# sestting the columns to then be scaled. \n",
    "cont_columns = ['population', 'gps_height', 'week', 'month', 'year', 'age'] \n",
    "\n",
    "\n",
    "# better scaler than the standard scaler --> as it changes the outlier. \n",
    "scaled = MinMaxScaler()\n",
    "X_train[cont_columns] = scaled.fit_transform(X_train[cont_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code that will use all your CPUs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "VZFXBk_9pZj3",
    "outputId": "16beaf40-f3ab-485b-841a-7cf2ab3a4445"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:281: UserWarning: The total space of parameters 1 is smaller than n_iter=10. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 32 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 20 folds for each of 1 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of  20 | elapsed:   26.5s remaining:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  20 | elapsed:   27.0s remaining:   22.1s\n",
      "[Parallel(n_jobs=-1)]: Done  17 out of  20 | elapsed:   27.5s remaining:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:   27.6s finished\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy Score: 0.8111952861952861\n"
     ]
    }
   ],
   "source": [
    "# making a dictionary for the param_distribution of the model\n",
    "p_dist = {\n",
    "    'n_estimators': [325], \n",
    "    'max_depth': [20]\n",
    "}\n",
    "\n",
    "\n",
    "# Instantiating the model and inputting inside the randomized search CV. \n",
    "model = RandomForestClassifier(n_jobs=-1, random_state=42, criterion=\"entropy\")\n",
    "\n",
    "# Randomized search CV. \n",
    "search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=p_dist,\n",
    "    scoring='accuracy',\n",
    "    n_iter=10,\n",
    "    n_jobs=-1,\n",
    "    cv=20,\n",
    "    verbose=4,\n",
    "    return_train_score=True,\n",
    "    random_state=69\n",
    ")\n",
    "\n",
    "# fitting t o the training data. \n",
    "search.fit(X_train, y_train)\n",
    "print('Training Accuracy Score:', search.best_score_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oBcBqXatpfiE"
   },
   "outputs": [],
   "source": [
    " # encoding and transforming the X_val\n",
    "X_val = encoder.transform(X_val)\n",
    "\n",
    "# scaling and fiting the continous columns. \n",
    "X_val[cont_columns] = scaled.fit_transform(X_val[cont_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TB2eLwF-rPyC",
    "outputId": "2afb96f1-baad-4840-db46-52fa09122330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Accuracy Score: 0.8116161616161616\n"
     ]
    }
   ],
   "source": [
    "# checking the score after scaling and fitting continous columsn. \n",
    "best = search.best_estimator_\n",
    "y_pred = best.predict(X_val)\n",
    "print('Validation Set Accuracy Score:', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yIV3srSnmMW0"
   },
   "outputs": [],
   "source": [
    "# getting X_test ready for making submission y_pred_test\n",
    "best = search.best_estimator_\n",
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "# scaling and fitting the y_pred test before exporting/ \n",
    "X_test[cont_columns] = scaled.fit_transform(X_test[cont_columns])\n",
    "y_pred_test = best.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# making the submission_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cf4dNmhArbLF"
   },
   "outputs": [],
   "source": [
    "submission = sample_submission.copy()\n",
    "submission['status_group'] = y_pred_test\n",
    "submission.to_csv('Submission_Kush.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KushRawal_Kaggle_Lambda.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
